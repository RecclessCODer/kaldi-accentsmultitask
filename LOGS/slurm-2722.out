2018-03-14 00:27:23,605 [steps/nnet3/train_raw_dnn.py:34 - <module> - INFO ] Starting raw DNN trainer (train_raw_dnn.py)
2018-03-14 00:27:23,611 [steps/nnet3/train_raw_dnn.py:172 - train - INFO ] Arguments for the experiment
{'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_average_posteriors': False,
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': 'exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/egs',
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/101/train_sp_hires',
 'final_effective_lrate': 0.00015,
 'frames_per_eg': 8,
 'image_augmentation_opts': None,
 'initial_effective_lrate': 0.0015,
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_param_change': 2.0,
 'minibatch_size': '256,128',
 'momentum': 0.0,
 'nj': 4,
 'num_epochs': 2.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 7,
 'num_jobs_initial': 4,
 'online_ivector_dir': 'exp/101/ivectors_train_sp',
 'preserve_model_interval': 50,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': False,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'targets_scp': 'exp/101/ali',
 'transform_dir': None,
 'use_dense_targets': False,
 'use_gpu': True}
2018-03-14 00:27:23,630 [steps/nnet3/train_raw_dnn.py:283 - train - INFO ] Preparing the initial network.
2018-03-14 00:27:26,851 [steps/nnet3/train_raw_dnn.py:322 - train - INFO ] Training will run for 2.0 epochs = 29 iterations
2018-03-14 00:27:26,851 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 0)
2018-03-14 00:27:26,854 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 0, learning rate is 0.006.
2018-03-14 00:30:52,349 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 1)
2018-03-14 00:30:52,354 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 1, learning rate is 0.00566436525772.
2018-03-14 00:33:16,263 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 2)
2018-03-14 00:33:16,269 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 2, learning rate is 0.0053475056288.
2018-03-14 00:35:37,870 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 3)
2018-03-14 00:35:37,876 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 3, learning rate is 0.00504837084987.
2018-03-14 00:38:03,408 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 4)
2018-03-14 00:38:03,414 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 4, learning rate is 0.00476596940835.
2018-03-14 00:40:25,102 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 5)
2018-03-14 00:40:25,108 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 5, learning rate is 0.00562420656999.
2018-03-14 00:43:26,333 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 6)
2018-03-14 00:43:26,344 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 6, learning rate is 0.00523372938645.
2018-03-14 00:46:23,317 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 7)
2018-03-14 00:46:23,323 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 7, learning rate is 0.00487036223682.
2018-03-14 00:49:24,242 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 8)
2018-03-14 00:49:24,248 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 8, learning rate is 0.00453222292679.
2018-03-14 00:52:20,414 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 9)
2018-03-14 00:52:20,420 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 9, learning rate is 0.00421755993893.
2018-03-14 00:55:21,398 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 10)
2018-03-14 00:55:21,404 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 10, learning rate is 0.00392474336011.
2018-03-14 00:58:17,646 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 11)
2018-03-14 00:58:17,651 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 11, learning rate is 0.00365225643874.
2018-03-14 01:01:18,867 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 12)
2018-03-14 01:01:18,874 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 12, learning rate is 0.0033986877282.
2018-03-14 01:04:14,983 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 13)
2018-03-14 01:04:14,989 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 13, learning rate is 0.00316272377571.
2018-03-14 01:07:16,338 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 14)
2018-03-14 01:07:16,346 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 14, learning rate is 0.00294314231886.
2018-03-14 01:10:13,211 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 15)
2018-03-14 01:10:13,217 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 15, learning rate is 0.00328656714529.
2018-03-14 01:13:50,309 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 16)
2018-03-14 01:13:50,316 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 16, learning rate is 0.00301468895242.
2018-03-14 01:17:22,186 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 17)
2018-03-14 01:17:22,192 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 17, learning rate is 0.00276530162874.
2018-03-14 01:20:57,985 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 18)
2018-03-14 01:20:57,991 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 18, learning rate is 0.00253654463814.
2018-03-14 01:24:30,818 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 19)
2018-03-14 01:24:30,824 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 19, learning rate is 0.00232671135561.
2018-03-14 01:28:03,437 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 20)
2018-03-14 01:28:03,443 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 20, learning rate is 0.0021342363351.
2018-03-14 01:33:42,885 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 21)
2018-03-14 01:33:42,892 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 21, learning rate is 0.00195768363062.
2018-03-14 01:37:14,533 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 22)
2018-03-14 01:37:14,539 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 22, learning rate is 0.00179573608347.
2018-03-14 01:40:50,612 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 23)
2018-03-14 01:40:50,618 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 23, learning rate is 0.00164718549568.
2018-03-14 01:44:23,746 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 24)
2018-03-14 01:44:23,752 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 24, learning rate is 0.00151092361631.
2018-03-14 01:47:56,476 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 25)
2018-03-14 01:47:56,484 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 25, learning rate is 0.00161692285236.
2018-03-14 01:52:11,088 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 26)
2018-03-14 01:52:11,095 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 26, learning rate is 0.00146197282161.
2018-03-14 01:56:20,042 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 27)
2018-03-14 01:56:20,049 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 27, learning rate is 0.00132187168238.
2018-03-14 02:00:30,329 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 28)
2018-03-14 02:00:30,337 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 28, learning rate is 0.00105.
2018-03-14 02:04:44,058 [steps/nnet3/train_raw_dnn.py:395 - train - INFO ] Doing final combination to produce final.raw
2018-03-14 02:04:44,058 [steps/libs/nnet3/train/frame_level_objf/common.py:466 - combine_models - INFO ] Combining set([16, 17, 18, 19, 20, 21, 22, 23, 24, 25, 26, 27, 28, 29]) models.
2018-03-14 02:14:57,254 [steps/nnet3/train_raw_dnn.py:417 - train - INFO ] Cleaning up the experiment directory exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents
exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents: num-iters=29 nj=4..7 num-params=52.1M combine=-1.83->-1.72
steps/nnet3/train_raw_dnn.py --stage=-10 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 2 --trainer.optimization.num-jobs-initial=4 --trainer.optimization.num-jobs-final=7 --trainer.optimization.initial-effective-lrate=0.0015 --trainer.optimization.final-effective-lrate=0.00015 --trainer.optimization.minibatch-size=256,128 --trainer.samples-per-iter=400000 --trainer.max-param-change=2.0 --trainer.srand=0 --feat-dir data/101/train_sp_hires --feat.online-ivector-dir exp/101/ivectors_train_sp --egs.dir exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/egs --use-dense-targets false --targets-scp exp/101/ali --cleanup.remove-egs false --cleanup.preserve-model-interval 50 --use-gpu true --dir=exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents
['steps/nnet3/train_raw_dnn.py', '--stage=-10', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '2', '--trainer.optimization.num-jobs-initial=4', '--trainer.optimization.num-jobs-final=7', '--trainer.optimization.initial-effective-lrate=0.0015', '--trainer.optimization.final-effective-lrate=0.00015', '--trainer.optimization.minibatch-size=256,128', '--trainer.samples-per-iter=400000', '--trainer.max-param-change=2.0', '--trainer.srand=0', '--feat-dir', 'data/101/train_sp_hires', '--feat.online-ivector-dir', 'exp/101/ivectors_train_sp', '--egs.dir', 'exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/egs', '--use-dense-targets', 'false', '--targets-scp', 'exp/101/ali', '--cleanup.remove-egs', 'false', '--cleanup.preserve-model-interval', '50', '--use-gpu', 'true', '--dir=exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents']
nnet3-am-init exp/101/ali/final.mdl - exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101/final.mdl 
nnet3-copy '--edits=rename-node old-name=output-0 new-name=output' exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/final.raw - 
LOG (nnet3-copy[5.2.204~1-08848]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/final.raw to -
LOG (nnet3-am-init[5.2.204~1-08848]:main():nnet3-am-init.cc:96) Initialized am-nnet (neural net acoustic model) and wrote to exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101/final.mdl
./run_multitask_with_separate_accents.sh: compute average posterior and readjust priors for language 01-recognition.
steps/nnet3/adjust_priors.sh exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101 exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/egs_1
nnet3-am-init exp/102/ali/final.mdl - exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102/final.mdl 
nnet3-copy '--edits=rename-node old-name=output-1 new-name=output' exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/final.raw - 
LOG (nnet3-copy[5.2.204~1-08848]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/final.raw to -
LOG (nnet3-am-init[5.2.204~1-08848]:main():nnet3-am-init.cc:96) Initialized am-nnet (neural net acoustic model) and wrote to exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102/final.mdl
./run_multitask_with_separate_accents.sh: compute average posterior and readjust priors for language 01-recognition.
steps/nnet3/adjust_priors.sh exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102 exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/egs_2
nnet3-am-init exp/103/ali/final.mdl - exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103/final.mdl 
nnet3-copy '--edits=rename-node old-name=output-2 new-name=output' exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/final.raw - 
LOG (nnet3-copy[5.2.204~1-08848]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/final.raw to -
LOG (nnet3-am-init[5.2.204~1-08848]:main():nnet3-am-init.cc:96) Initialized am-nnet (neural net acoustic model) and wrote to exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103/final.mdl
./run_multitask_with_separate_accents.sh: compute average posterior and readjust priors for language 01-recognition.
steps/nnet3/adjust_priors.sh exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103 exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/egs_3
nnet3-am-init exp/104/ali/final.mdl - exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104/final.mdl 
nnet3-copy '--edits=rename-node old-name=output-3 new-name=output' exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/final.raw - 
LOG (nnet3-copy[5.2.204~1-08848]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/final.raw to -
LOG (nnet3-am-init[5.2.204~1-08848]:main():nnet3-am-init.cc:96) Initialized am-nnet (neural net acoustic model) and wrote to exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104/final.mdl
./run_multitask_with_separate_accents.sh: compute average posterior and readjust priors for language 01-recognition.
steps/nnet3/adjust_priors.sh exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104 exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/egs_4
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/101/ivectors_dev /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/101/dev_hires exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101/decode_dev
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101/decode_dev
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101/decode_dev/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,6,32) and mean=12.9
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101/decode_dev/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/101/dev_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101/decode_dev
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/102/ivectors_dev /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/102/dev_hires exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102/decode_dev
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102/decode_dev
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102/decode_dev/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(3,10,41) and mean=16.5
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102/decode_dev/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/102/dev_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102/decode_dev
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/103/ivectors_dev /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/103/dev_hires exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103/decode_dev
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103/decode_dev
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103/decode_dev/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(3,11,60) and mean=26.4
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103/decode_dev/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/103/dev_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103/decode_dev
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/104/ivectors_dev /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/104/dev_hires exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104/decode_dev
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104/decode_dev
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104/decode_dev/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(3,10,53) and mean=22.3
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104/decode_dev/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/104/dev_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104/decode_dev
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
