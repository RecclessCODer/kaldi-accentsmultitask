steps/nnet3/xconfig_to_configs.py --xconfig-file exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs/network.xconfig --config-dir exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs/ --nnet-edits=rename-node old-name=output-0 new-name=output
nnet3-init exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.config exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw 
LOG (nnet3-init[5.2.204~1-08848]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw
nnet3-info "nnet3-copy --edits='rename-node old-name=output-0 new-name=output' exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw - |" 
nnet3-copy '--edits=rename-node old-name=output-0 new-name=output' exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw - 
LOG (nnet3-copy[5.2.204~1-08848]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw to -
nnet3-init exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.config exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw 
LOG (nnet3-init[5.2.204~1-08848]:main():nnet3-init.cc:80) Initialized raw neural net and wrote it to exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw
nnet3-info "nnet3-copy --edits='rename-node old-name=output-0 new-name=output' exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw - |" 
nnet3-copy '--edits=rename-node old-name=output-0 new-name=output' exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw - 
LOG (nnet3-copy[5.2.204~1-08848]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/configs//ref.raw to -
./multitask_run_2_base.sh: calling get_egs.sh for generating examples with alignments as output
steps/nnet3/get_egs.sh --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/101-recog-min/nnet3/ivectors_cv_train_nz_sp --transform-dir exp/101-recog-min/tri4_cv_train_nz_ali --left-context 30 --right-context 22 --num-utts-subset 300 --nj 20 --samples-per-iter 400000 --cmd run.pl --generate-egs-scp true --frames-per-eg 8 data/101-recog-min/cv_train_nz_sp_hires exp/101-recog-min/tri4_cv_train_nz_ali exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns
File data/101-recog-min/cv_train_nz_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs.sh: feature type is raw
feat-to-dim scp:exp/101-recog-min/nnet3/ivectors_cv_train_nz_sp/ivector_online.scp - 
steps/nnet3/get_egs.sh: working out number of frames of training data
steps/nnet3/get_egs.sh: working out feature dim
steps/nnet3/get_egs.sh: creating 12 archives, each with 387321 egs, with
steps/nnet3/get_egs.sh:   8 labels per example, and (left,right) context = (30,22)
steps/nnet3/get_egs.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns/ali.ark,exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns/ali.scp 
LOG (copy-int-vector[5.2.204~1-08848]:main():copy-int-vector.cc:83) Copied 92661 vectors of int32.
steps/nnet3/get_egs.sh: Getting validation and training subset examples.
steps/nnet3/get_egs.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
nnet3-copy-egs ark:- ark,scp:exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns/combine.egs,exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns/combine.scp 
LOG (nnet3-copy-egs[5.2.204~1-08848]:main():nnet3-copy-egs.cc:436) Read 7500 neural-network training examples, wrote 7500, 0 examples had errors.
rm: cannot remove 'exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns/train_combine.scp': No such file or directory
rm: cannot remove 'exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns/valid_combine.scp': No such file or directory
steps/nnet3/get_egs.sh: Generating training examples on disk
steps/nnet3/get_egs.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs.sh: removing temporary archives
steps/nnet3/get_egs.sh: removing temporary alignments and transforms
steps/nnet3/get_egs.sh: Finished preparing training examples
./multitask_run_2_base.sh: calling get_egs.sh for generating examples with alignments as output
steps/nnet3/get_egs_mod.sh --cmvn-opts --norm-means=false --norm-vars=false --online-ivector-dir exp/102-cla-min/nnet3/ivectors_cv_trainx_nz_sp --transform-dir exp/102-cla-min/ali --left-context 30 --right-context 22 --num-utts-subset 300 --nj 20 --num-pdfs 16 --samples-per-iter 400000 --cmd run.pl --generate-egs-scp true --frames-per-eg 8 data/102-cla-min/cv_trainx_nz_sp_hires exp/102-cla-min/ali exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_accents
File data/102-cla-min/cv_trainx_nz_sp_hires/utt2uniq exists, so augmenting valid_uttlist to
include all perturbed versions of the same 'real' utterances.
steps/nnet3/get_egs_mod.sh: feature type is raw
feat-to-dim scp:exp/102-cla-min/nnet3/ivectors_cv_trainx_nz_sp/ivector_online.scp - 
steps/nnet3/get_egs_mod.sh: working out number of frames of training data
steps/nnet3/get_egs_mod.sh: working out feature dim
steps/nnet3/get_egs_mod.sh: creating 12 archives, each with 387321 egs, with
steps/nnet3/get_egs_mod.sh:   8 labels per example, and (left,right) context = (30,22)
steps/nnet3/get_egs_mod.sh: copying data alignments
copy-int-vector ark:- ark,scp:exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_accents/ali.ark,exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_accents/ali.scp 
LOG (copy-int-vector[5.2.204~1-08848]:main():copy-int-vector.cc:83) Copied 92660 vectors of int32.
steps/nnet3/get_egs_mod.sh: Getting validation and training subset examples.
steps/nnet3/get_egs_mod.sh: ... extracting validation and training-subset alignments.
... Getting subsets of validation examples for diagnostics and combination.
nnet3-copy-egs ark:- ark,scp:exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_accents/combine.egs,exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_accents/combine.scp 
LOG (nnet3-copy-egs[5.2.204~1-08848]:main():nnet3-copy-egs.cc:436) Read 7500 neural-network training examples, wrote 7500, 0 examples had errors.
rm: cannot remove 'exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_accents/train_combine.scp': No such file or directory
rm: cannot remove 'exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_accents/valid_combine.scp': No such file or directory
steps/nnet3/get_egs_mod.sh: Generating training examples on disk
steps/nnet3/get_egs_mod.sh: recombining and shuffling order of archives on disk
steps/nnet3/get_egs_mod.sh: removing temporary archives
steps/nnet3/get_egs_mod.sh: removing temporary alignments and transforms
steps/nnet3/get_egs_mod.sh: Finished preparing training examples
steps/nnet3/multilingual/combine_egs.sh --lang2weight '0.5,0.5' --cmd run.pl --mem 4G --samples-per-iter 400000 2 exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_accents exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs
steps/nnet3/multilingual/combine_egs.sh: allocating multilingual examples for training.
steps/nnet3/multilingual/combine_egs.sh: combine combine.scp examples from all langs in exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs/combine.scp.
steps/nnet3/multilingual/combine_egs.sh: combine train_diagnostic.scp examples from all langs in exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs/train_diagnostic.scp.
steps/nnet3/multilingual/combine_egs.sh: combine valid_diagnostic.scp examples from all langs in exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs/valid_diagnostic.scp.
steps/nnet3/multilingual/combine_egs.sh: Finished preparing multilingual training example.
2018-03-17 14:42:58,368 [steps/nnet3/train_raw_dnn.py:34 - <module> - INFO ] Starting raw DNN trainer (train_raw_dnn.py)
2018-03-17 14:42:58,374 [steps/nnet3/train_raw_dnn.py:172 - train - INFO ] Arguments for the experiment
{'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_average_posteriors': False,
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext',
 'do_final_combination': True,
 'dropout_schedule': None,
 'egs_command': None,
 'egs_dir': 'exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs',
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/101-recog-min/cv_train_nz_sp_hires',
 'final_effective_lrate': 0.00015,
 'frames_per_eg': 8,
 'image_augmentation_opts': None,
 'initial_effective_lrate': 0.0015,
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_param_change': 2.0,
 'minibatch_size': '256,128',
 'momentum': 0.0,
 'nj': 4,
 'num_epochs': 2.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 8,
 'num_jobs_initial': 2,
 'online_ivector_dir': 'exp/101-recog-min/nnet3/ivectors_cv_train_nz_sp',
 'preserve_model_interval': 50,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': False,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': -10,
 'targets_scp': 'exp/101-recog-min/tri4_cv_train_nz_ali',
 'transform_dir': None,
 'use_dense_targets': False,
 'use_gpu': True}
2018-03-17 14:42:58,392 [steps/nnet3/train_raw_dnn.py:283 - train - INFO ] Preparing the initial network.
2018-03-17 14:43:00,800 [steps/nnet3/train_raw_dnn.py:322 - train - INFO ] Training will run for 2.0 epochs = 73 iterations
2018-03-17 14:43:00,801 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 0)
2018-03-17 14:43:00,804 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 0, learning rate is 0.003.
2018-03-17 14:47:57,072 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 1)
2018-03-17 14:47:57,079 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 1, learning rate is 0.00296269177709.
2018-03-17 14:50:43,831 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 2)
2018-03-17 14:50:43,837 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 2, learning rate is 0.00292584752202.
2018-03-17 14:53:34,003 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 3)
2018-03-17 14:53:34,009 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 3, learning rate is 0.00288946146484.
2018-03-17 14:56:10,038 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 4)
2018-03-17 14:56:10,044 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 4, learning rate is 0.00285352790737.
2018-03-17 14:58:40,475 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 5)
2018-03-17 14:58:40,484 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 5, learning rate is 0.00281804122229.
2018-03-17 15:01:19,935 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 6)
2018-03-17 15:01:19,942 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 6, learning rate is 0.00278299585226.
2018-03-17 15:03:49,310 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 7)
2018-03-17 15:03:49,316 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 7, learning rate is 0.00412257946358.
2018-03-17 15:07:26,679 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 8)
2018-03-17 15:07:26,685 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 8, learning rate is 0.00404591599771.
2018-03-17 15:10:53,415 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 9)
2018-03-17 15:10:53,424 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 9, learning rate is 0.00397067816525.
2018-03-17 15:18:11,747 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 10)
2018-03-17 15:18:11,752 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 10, learning rate is 0.00389683945512.
2018-03-17 15:21:50,259 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 11)
2018-03-17 15:21:50,265 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 11, learning rate is 0.00382437384925.
2018-03-17 15:25:37,895 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 12)
2018-03-17 15:25:37,913 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 12, learning rate is 0.00375325581341.
2018-03-17 15:31:21,745 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 13)
2018-03-17 15:31:21,752 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 13, learning rate is 0.00368346028818.
2018-03-17 15:38:09,994 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 14)
2018-03-17 15:38:10,008 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 14, learning rate is 0.00361496268017.
2018-03-17 15:41:39,073 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 15)
2018-03-17 15:41:39,080 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 15, learning rate is 0.00354773885332.
2018-03-17 15:45:16,922 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 16)
2018-03-17 15:45:16,930 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 16, learning rate is 0.00348176512039.
2018-03-17 15:48:42,677 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 17)
2018-03-17 15:48:42,683 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 17, learning rate is 0.00341701823465.
2018-03-17 15:52:28,694 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 18)
2018-03-17 15:52:28,704 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 18, learning rate is 0.00335347538166.
2018-03-17 15:56:01,413 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 19)
2018-03-17 15:56:01,419 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 19, learning rate is 0.0043881522283.
2018-03-17 16:00:49,725 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 20)
2018-03-17 16:00:49,731 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 20, learning rate is 0.0042796881078.
2018-03-17 16:07:07,043 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 21)
2018-03-17 16:07:07,049 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 21, learning rate is 0.00417390494841.
2018-03-17 16:11:48,250 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 22)
2018-03-17 16:11:48,255 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 22, learning rate is 0.00407073648348.
2018-03-17 16:16:16,585 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 23)
2018-03-17 16:16:16,591 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 23, learning rate is 0.00397011808433.
2018-03-17 16:21:02,491 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 24)
2018-03-17 16:21:02,497 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 24, learning rate is 0.00387198671971.
2018-03-17 16:25:45,886 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 25)
2018-03-17 16:25:45,892 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 25, learning rate is 0.00377628091639.
2018-03-17 16:30:28,826 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 26)
2018-03-17 16:30:28,833 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 26, learning rate is 0.00368294072055.
2018-03-17 16:35:16,364 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 27)
2018-03-17 16:35:16,370 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 27, learning rate is 0.00359190766032.
2018-03-17 16:39:53,410 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 28)
2018-03-17 16:39:53,417 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 28, learning rate is 0.00350312470909.
2018-03-17 16:44:21,195 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 29)
2018-03-17 16:44:21,201 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 29, learning rate is 0.0034165362498.
2018-03-17 16:49:06,648 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 30)
2018-03-17 16:49:06,655 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 30, learning rate is 0.00333208804012.
2018-03-17 16:53:45,140 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 31)
2018-03-17 16:53:45,146 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 31, learning rate is 0.00406215897306.
2018-03-17 16:59:42,297 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 32)
2018-03-17 16:59:42,305 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 32, learning rate is 0.00393704119514.
2018-03-17 17:05:30,871 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 33)
2018-03-17 17:05:30,879 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 33, learning rate is 0.00381577714585.
2018-03-17 17:11:09,108 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 34)
2018-03-17 17:11:09,114 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 34, learning rate is 0.00369824812724.
2018-03-17 17:16:47,011 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 35)
2018-03-17 17:16:47,016 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 35, learning rate is 0.00358433909735.
2018-03-17 17:22:40,276 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 36)
2018-03-17 17:22:40,282 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 36, learning rate is 0.0034739385576.
2018-03-17 17:28:25,974 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 37)
2018-03-17 17:28:25,981 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 37, learning rate is 0.00336693844366.
2018-03-17 17:34:06,025 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 38)
2018-03-17 17:34:06,034 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 38, learning rate is 0.00326323401967.
2018-03-17 17:39:46,230 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 39)
2018-03-17 17:39:46,238 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 39, learning rate is 0.00316272377571.
2018-03-17 17:45:37,579 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 40)
2018-03-17 17:45:37,594 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 40, learning rate is 0.00306530932847.
2018-03-17 17:53:31,532 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 41)
2018-03-17 17:53:31,537 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 41, learning rate is 0.00297089532489.
2018-03-17 17:59:12,370 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 42)
2018-03-17 17:59:12,376 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 42, learning rate is 0.00287938934889.
2018-03-17 18:04:46,354 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 43)
2018-03-17 18:04:46,363 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 43, learning rate is 0.00334884219705.
2018-03-17 18:09:16,974 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 44)
2018-03-17 18:09:16,993 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 44, learning rate is 0.00322545016007.
2018-03-17 18:13:52,501 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 45)
2018-03-17 18:13:52,510 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 45, learning rate is 0.00310660464809.
2018-03-17 18:17:29,855 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 46)
2018-03-17 18:17:29,866 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 46, learning rate is 0.00299213813904.
2018-03-17 18:21:54,753 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 47)
2018-03-17 18:21:54,763 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 47, learning rate is 0.00288188928341.
2018-03-17 18:24:38,918 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 48)
2018-03-17 18:24:38,928 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 48, learning rate is 0.00277570267678.
2018-03-17 18:30:15,664 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 49)
2018-03-17 18:30:15,677 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 49, learning rate is 0.0026734286408.
2018-03-17 18:35:41,353 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 50)
2018-03-17 18:35:41,362 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 50, learning rate is 0.00257492301219.
2018-03-17 18:38:21,956 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 51)
2018-03-17 18:38:21,966 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 51, learning rate is 0.00248004693955.
2018-03-17 18:42:57,216 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 52)
2018-03-17 18:42:57,228 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 52, learning rate is 0.00238866668761.
2018-03-17 18:48:36,183 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 53)
2018-03-17 18:48:36,194 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 53, learning rate is 0.00230065344873.
2018-03-17 18:53:01,191 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 54)
2018-03-17 18:53:01,201 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 54, learning rate is 0.00221588316135.
2018-03-17 18:56:35,688 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 55)
2018-03-17 18:56:35,698 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 55, learning rate is 0.00248994239094.
2018-03-17 19:00:20,792 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 56)
2018-03-17 19:00:20,802 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 56, learning rate is 0.00238323879562.
2018-03-17 19:04:53,367 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 57)
2018-03-17 19:04:53,386 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 57, learning rate is 0.0022811078592.
2018-03-17 19:09:20,752 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 58)
2018-03-17 19:09:20,761 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 58, learning rate is 0.0021833536257.
2018-03-17 19:14:54,278 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 59)
2018-03-17 19:14:54,288 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 59, learning rate is 0.00208978853657.
2018-03-17 19:19:35,268 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 60)
2018-03-17 19:19:35,277 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 60, learning rate is 0.0020002330709.
2018-03-17 19:24:16,251 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 61)
2018-03-17 19:24:16,261 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 61, learning rate is 0.00191451540091.
2018-03-17 19:30:47,846 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 62)
2018-03-17 19:30:47,857 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 62, learning rate is 0.00183247106233.
2018-03-17 19:35:28,519 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 63)
2018-03-17 19:35:28,529 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 63, learning rate is 0.00175394263878.
2018-03-17 19:42:08,930 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 64)
2018-03-17 19:42:08,941 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 64, learning rate is 0.00167877945981.
2018-03-17 19:46:41,234 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 65)
2018-03-17 19:46:41,247 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 65, learning rate is 0.00160683731177.
2018-03-17 19:52:21,390 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 66)
2018-03-17 19:52:21,400 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 66, learning rate is 0.00153797816109.
2018-03-17 19:56:53,637 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 67)
2018-03-17 19:56:53,648 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 67, learning rate is 0.00168236558801.
2018-03-17 20:01:25,417 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 68)
2018-03-17 20:01:25,429 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 68, learning rate is 0.0016002257186.
2018-03-17 20:06:05,052 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 69)
2018-03-17 20:06:05,061 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 69, learning rate is 0.0015220962487.
2018-03-17 20:11:42,302 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 70)
2018-03-17 20:11:42,313 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 70, learning rate is 0.00144778137445.
2018-03-17 20:17:14,458 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 71)
2018-03-17 20:17:14,468 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 71, learning rate is 0.00137709485192.
2018-03-17 20:23:54,145 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 72)
2018-03-17 20:23:54,155 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 72, learning rate is 0.0012.
2018-03-17 20:28:36,670 [steps/nnet3/train_raw_dnn.py:395 - train - INFO ] Doing final combination to produce final.raw
2018-03-17 20:28:36,670 [steps/libs/nnet3/train/frame_level_objf/common.py:466 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) models.
2018-03-17 20:37:48,895 [steps/nnet3/train_raw_dnn.py:417 - train - INFO ] Cleaning up the experiment directory exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext
exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext: num-iters=73 nj=2..8 num-params=29.7M combine=-0.38->-0.35
slurmstepd: *** JOB 2998 ON dhvani CANCELLED AT 2018-03-17T20:38:27 DUE TO TIME LIMIT ***


nnet3-am-init exp/101-recog-min/tri4_cv_train_nz_ali/final.mdl - exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/final.mdl 
nnet3-copy '--edits=rename-node old-name=output-0 new-name=output' exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/final.raw - 
LOG (nnet3-copy[5.2.204~1-08848]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/final.raw to -
LOG (nnet3-am-init[5.2.204~1-08848]:main():nnet3-am-init.cc:96) Initialized am-nnet (neural net acoustic model) and wrote to exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/final.mdl
./multitask_run_2_base.sh: compute average posterior and readjust priors for language 01-recognition.
steps/nnet3/adjust_priors.sh exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/egs_aligns
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/101-recog-min/nnet3/ivectors_cv_dev_nz /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/101-recog-min/cv_dev_nz_hires exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,3,21) and mean=8.8
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/101-recog-min/cv_dev_nz_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/101-recog-min/nnet3/ivectors_cv_test_onlynz /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/101-recog-min/cv_test_onlynz_hires exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,25) and mean=10.2
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/101-recog-min/cv_test_onlynz_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
%WER 31.42 [ 3263 / 10386, 149 ins, 1316 del, 1798 sub ] exp/nnet3/multitask/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 36.86 [ 1876 / 5089, 106 ins, 737 del, 1033 sub ] exp/nnet3/multitask/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 33.35 [ 3464 / 10386, 174 ins, 1381 del, 1909 sub ] exp/nnet3/multitask_0.4_0.6/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 38.65 [ 1967 / 5089, 106 ins, 788 del, 1073 sub ] exp/nnet3/multitask_0.4_0.6/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 29.33 [ 3046 / 10386, 228 ins, 1030 del, 1788 sub ] exp/nnet3/multitask_0.6_0.4/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 33.19 [ 1689 / 5089, 125 ins, 498 del, 1066 sub ] exp/nnet3/multitask_0.6_0.4/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 29.42 [ 3056 / 10386, 194 ins, 1089 del, 1773 sub ] exp/nnet3/multitask_0.7_0.3/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 31.81 [ 1619 / 5089, 109 ins, 524 del, 986 sub ] exp/nnet3/multitask_0.7_0.3/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 28.01 [ 2909 / 10386, 183 ins, 999 del, 1727 sub ] exp/nnet3/multitask_0.8_0.2/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 31.48 [ 1602 / 5089, 114 ins, 503 del, 985 sub ] exp/nnet3/multitask_0.8_0.2/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 27.97 [ 2905 / 10386, 181 ins, 986 del, 1738 sub ] exp/nnet3/multitask_0.9_0.1/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 30.16 [ 1535 / 5089, 98 ins, 479 del, 958 sub ] exp/nnet3/multitask_0.9_0.1/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 27.15 [ 2820 / 10386, 187 ins, 877 del, 1756 sub ] exp/nnet3/multitask_accentOutputAt2_0.5_0.5/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 30.58 [ 1556 / 5089, 104 ins, 459 del, 993 sub ] exp/nnet3/multitask_accentOutputAt2_0.5_0.5/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 27.69 [ 2876 / 10386, 215 ins, 879 del, 1782 sub ] exp/nnet3/multitask_accentOutputAt3_0.5_0.5/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 31.07 [ 1581 / 5089, 95 ins, 469 del, 1017 sub ] exp/nnet3/multitask_accentOutputAt3_0.5_0.5/101-recognition/decode_cv_test_onlynz/wer_7_0.5
%WER 27.63 [ 2870 / 10386, 207 ins, 901 del, 1762 sub ] exp/nnet3/multitask_accentOutputAt3_0.6_0.4/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 31.74 [ 1615 / 5089, 120 ins, 470 del, 1025 sub ] exp/nnet3/multitask_accentOutputAt3_0.6_0.4/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 27.52 [ 2858 / 10386, 195 ins, 893 del, 1770 sub ] exp/nnet3/multitask_accentOutputAt3_0.7_0.3/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 30.95 [ 1575 / 5089, 126 ins, 442 del, 1007 sub ] exp/nnet3/multitask_accentOutputAt3_0.7_0.3/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 28.73 [ 2984 / 10386, 201 ins, 975 del, 1808 sub ] exp/nnet3/multitask_accentOutputAt4_0.4_0.6/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 34.29 [ 1745 / 5089, 128 ins, 557 del, 1060 sub ] exp/nnet3/multitask_accentOutputAt4_0.4_0.6/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 28.16 [ 2925 / 10386, 207 ins, 918 del, 1800 sub ] exp/nnet3/multitask_accentOutputAt4_0.5_0.5/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 33.35 [ 1697 / 5089, 143 ins, 506 del, 1048 sub ] exp/nnet3/multitask_accentOutputAt4_0.5_0.5/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 27.63 [ 2870 / 10386, 207 ins, 901 del, 1762 sub ] exp/nnet3/multitask_accentOutputAt4_0.6_0.4/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 31.74 [ 1615 / 5089, 120 ins, 470 del, 1025 sub ] exp/nnet3/multitask_accentOutputAt4_0.6_0.4/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 27.52 [ 2858 / 10386, 195 ins, 893 del, 1770 sub ] exp/nnet3/multitask_accentOutputAt4_0.7_0.3/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 30.95 [ 1575 / 5089, 126 ins, 442 del, 1007 sub ] exp/nnet3/multitask_accentOutputAt4_0.7_0.3/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 29.96 [ 3112 / 10386, 205 ins, 1080 del, 1827 sub ] exp/nnet3/multitask_accentOutputAt5_0.4_0.6/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 34.98 [ 1780 / 5089, 137 ins, 564 del, 1079 sub ] exp/nnet3/multitask_accentOutputAt5_0.4_0.6/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 29.02 [ 3014 / 10386, 196 ins, 1015 del, 1803 sub ] exp/nnet3/multitask_accentOutputAt5_0.5_0.5/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 34.13 [ 1737 / 5089, 122 ins, 555 del, 1060 sub ] exp/nnet3/multitask_accentOutputAt5_0.5_0.5/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 28.06 [ 2914 / 10386, 195 ins, 994 del, 1725 sub ] exp/nnet3/multitask_accentOutputAt5_0.6_0.4/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 32.36 [ 1647 / 5089, 124 ins, 524 del, 999 sub ] exp/nnet3/multitask_accentOutputAt5_0.6_0.4/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 28.11 [ 2920 / 10386, 199 ins, 970 del, 1751 sub ] exp/nnet3/multitask_accentOutputAt5_0.7_0.3/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 32.68 [ 1663 / 5089, 115 ins, 548 del, 1000 sub ] exp/nnet3/multitask_accentOutputAt5_0.7_0.3/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 31.02 [ 3222 / 10386, 186 ins, 1177 del, 1859 sub ] exp/nnet3/multitask_bottleneck_300_0.5_0.5/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 36.69 [ 1867 / 5089, 104 ins, 745 del, 1018 sub ] exp/nnet3/multitask_bottleneck_300_0.5_0.5/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 31.13 [ 3233 / 10386, 194 ins, 1212 del, 1827 sub ] exp/nnet3/multitask_bottleneck_512_0.5_0.5/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 36.37 [ 1851 / 5089, 104 ins, 705 del, 1042 sub ] exp/nnet3/multitask_bottleneck_512_0.5_0.5/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 31.22 [ 3243 / 10386, 212 ins, 1130 del, 1901 sub ] exp/nnet3/multitask_removedOneLayer_0.5_0.5/101-recognition/decode_cv_dev_nz/wer_7_0.0
%WER 33.88 [ 1724 / 5089, 120 ins, 528 del, 1076 sub ] exp/nnet3/multitask_removedOneLayer_0.5_0.5/101-recognition/decode_cv_test_onlynz/wer_7_0.0
%WER 22.80 [ 2368 / 10386, 249 ins, 465 del, 1654 sub ] exp/nnet3_combined/multitask_acc1024btn_tdnn1024_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz/wer_8_0.0
%WER 61.01 [ 496 / 813, 29 ins, 158 del, 309 sub ] exp/nnet3_combined/multitask_acc1024btn_tdnn1024_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlyindian/wer_9_1.0
%WER 27.51 [ 1400 / 5089, 125 ins, 258 del, 1017 sub ] exp/nnet3_combined/multitask_acc1024btn_tdnn1024_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz/wer_8_0.5
%WER 23.21 [ 2411 / 10386, 221 ins, 511 del, 1679 sub ] exp/nnet3_combined/multitask_acc300btn_tdnn300_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz/wer_7_0.5
%WER 64.21 [ 522 / 813, 39 ins, 164 del, 319 sub ] exp/nnet3_combined/multitask_acc300btn_tdnn300_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlyindian/wer_7_0.5
%WER 30.56 [ 1555 / 5089, 131 ins, 325 del, 1099 sub ] exp/nnet3_combined/multitask_acc300btn_tdnn300_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz/wer_7_0.5
%WER 23.72 [ 2464 / 10386, 235 ins, 527 del, 1702 sub ] exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz/wer_7_0.5
%WER 30.14 [ 1534 / 5089, 134 ins, 330 del, 1070 sub ] exp/nnet3_combined/multitask_acc300btn_tdnn512_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz/wer_7_0.0
%WER 22.85 [ 2373 / 10386, 236 ins, 463 del, 1674 sub ] exp/nnet3_combined/multitask_acc512btn_tdnn1024_0.5_0.5_withcontext/101-recog-min/decode_cv_dev_nz/wer_8_0.0
%WER 62.12 [ 505 / 813, 33 ins, 162 del, 310 sub ] exp/nnet3_combined/multitask_acc512btn_tdnn1024_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlyindian/wer_8_0.0
%WER 29.00 [ 1476 / 5089, 143 ins, 284 del, 1049 sub ] exp/nnet3_combined/multitask_acc512btn_tdnn1024_0.5_0.5_withcontext/101-recog-min/decode_cv_test_onlynz/wer_8_0.0
%WER 32.53 [ 1917 / 5893, 163 ins, 574 del, 1180 sub ] exp/nnet3_separate_accents/multitask_separate_accents_0.14_nz/101/decode_dev/wer_7_0.0
%WER 58.35 [ 1663 / 2850, 22 ins, 1063 del, 578 sub ] exp/nnet3_separate_accents/multitask_separate_accents_0.14_nz/102/decode_dev/wer_7_0.0
%WER 67.43 [ 617 / 915, 15 ins, 362 del, 240 sub ] exp/nnet3_separate_accents/multitask_separate_accents_0.14_nz/103/decode_dev/wer_7_0.0
%WER 55.32 [ 442 / 799, 6 ins, 273 del, 163 sub ] exp/nnet3_separate_accents/multitask_separate_accents_0.14_nz/104/decode_dev/wer_7_0.0
%WER 33.33 [ 1964 / 5893, 137 ins, 615 del, 1212 sub ] exp/nnet3_separate_accents/multitask_separate_accents_variable_nz/101/decode_dev/wer_7_0.0
%WER 59.75 [ 1703 / 2850, 18 ins, 1069 del, 616 sub ] exp/nnet3_separate_accents/multitask_separate_accents_variable_nz/102/decode_dev/wer_7_0.0
%WER 68.09 [ 623 / 915, 11 ins, 366 del, 246 sub ] exp/nnet3_separate_accents/multitask_separate_accents_variable_nz/103/decode_dev/wer_7_0.0
%WER 56.20 [ 449 / 799, 6 ins, 273 del, 170 sub ] exp/nnet3_separate_accents/multitask_separate_accents_variable_nz/104/decode_dev/wer_7_0.0
%WER 31.87 [ 1878 / 5893, 122 ins, 637 del, 1119 sub ] exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/101/decode_dev/wer_7_0.0
%WER 57.40 [ 1636 / 2850, 13 ins, 1041 del, 582 sub ] exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/102/decode_dev/wer_7_0.0
%WER 66.01 [ 604 / 915, 5 ins, 387 del, 212 sub ] exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/103/decode_dev/wer_7_0.0
%WER 50.81 [ 406 / 799, 8 ins, 249 del, 149 sub ] exp/nnet3_separate_accents/multitask_separate_accents_variable_nz_4_accents/104/decode_dev/wer_7_0.0
