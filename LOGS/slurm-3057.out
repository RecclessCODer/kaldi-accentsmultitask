2018-03-19 05:04:03,919 [steps/nnet3/train_raw_dnn.py:34 - <module> - INFO ] Starting raw DNN trainer (train_raw_dnn.py)
2018-03-19 05:04:03,929 [steps/nnet3/train_raw_dnn.py:172 - train - INFO ] Arguments for the experiment
{'backstitch_training_interval': 1,
 'backstitch_training_scale': 0.0,
 'cleanup': True,
 'cmvn_opts': '--norm-means=false --norm-vars=false',
 'combine_sum_to_one_penalty': 0.0,
 'command': 'run.pl --mem 4G',
 'compute_average_posteriors': False,
 'compute_per_dim_accuracy': False,
 'dir': 'exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0',
 'do_final_combination': True,
 'dropout_schedule': '0,0.6,0',
 'egs_command': None,
 'egs_dir': 'exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/egs',
 'egs_opts': None,
 'egs_stage': 0,
 'email': None,
 'exit_stage': None,
 'feat_dir': 'data/101-recog-min/cv_train_nz_sp_hires',
 'final_effective_lrate': 0.00015,
 'frames_per_eg': 8,
 'image_augmentation_opts': None,
 'initial_effective_lrate': 0.0015,
 'max_lda_jobs': 10,
 'max_models_combine': 20,
 'max_param_change': 2.0,
 'minibatch_size': '256,128',
 'momentum': 0.0,
 'nj': 4,
 'num_epochs': 2.0,
 'num_jobs_compute_prior': 10,
 'num_jobs_final': 8,
 'num_jobs_initial': 2,
 'online_ivector_dir': 'exp/101-recog-min/nnet3/ivectors_cv_train_nz_sp',
 'preserve_model_interval': 50,
 'presoftmax_prior_scale_power': -0.25,
 'prior_subset_size': 20000,
 'proportional_shrink': 0.0,
 'rand_prune': 4.0,
 'remove_egs': False,
 'reporting_interval': 0.1,
 'samples_per_iter': 400000,
 'shuffle_buffer_size': 5000,
 'srand': 0,
 'stage': 50,
 'targets_scp': 'exp/101-recog-min/tri4_cv_train_nz_ali',
 'transform_dir': None,
 'use_dense_targets': False,
 'use_gpu': True}
2018-03-19 05:04:03,973 [steps/nnet3/train_raw_dnn.py:322 - train - INFO ] Training will run for 2.0 epochs = 73 iterations
2018-03-19 05:04:03,974 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 50)
2018-03-19 05:04:03,979 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 50, learning rate is 0.00257492301219.
2018-03-19 05:10:48,437 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 51)
2018-03-19 05:10:48,445 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 51, learning rate is 0.00248004693955.
2018-03-19 05:17:34,055 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 52)
2018-03-19 05:17:34,061 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 52, learning rate is 0.00238866668761.
2018-03-19 05:24:35,029 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 53)
2018-03-19 05:24:35,036 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 53, learning rate is 0.00230065344873.
2018-03-19 05:31:15,325 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 54)
2018-03-19 05:31:15,338 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 54, learning rate is 0.00221588316135.
2018-03-19 05:37:49,534 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 55)
2018-03-19 05:37:49,542 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 55, learning rate is 0.00248994239094.
2018-03-19 05:45:43,024 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 56)
2018-03-19 05:45:43,029 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 56, learning rate is 0.00238323879562.
2018-03-19 05:53:27,317 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 57)
2018-03-19 05:53:27,323 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 57, learning rate is 0.0022811078592.
2018-03-19 06:00:56,503 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 58)
2018-03-19 06:00:56,511 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 58, learning rate is 0.0021833536257.
2018-03-19 06:08:38,525 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 59)
2018-03-19 06:08:38,532 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 59, learning rate is 0.00208978853657.
2018-03-19 06:16:25,187 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 60)
2018-03-19 06:16:25,199 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 60, learning rate is 0.0020002330709.
2018-03-19 06:26:39,526 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 61)
2018-03-19 06:26:39,536 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 61, learning rate is 0.00191451540091.
2018-03-19 06:34:13,110 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 62)
2018-03-19 06:34:13,119 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 62, learning rate is 0.00183247106233.
2018-03-19 06:42:01,661 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 63)
2018-03-19 06:42:01,669 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 63, learning rate is 0.00175394263878.
2018-03-19 06:49:34,544 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 64)
2018-03-19 06:49:34,555 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 64, learning rate is 0.00167877945981.
2018-03-19 06:57:06,875 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 65)
2018-03-19 06:57:06,885 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 65, learning rate is 0.00160683731177.
2018-03-19 07:04:51,636 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 66)
2018-03-19 07:04:51,647 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 66, learning rate is 0.00153797816109.
2018-03-19 07:10:23,303 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 67)
2018-03-19 07:10:23,313 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 67, learning rate is 0.00168236558801.
2018-03-19 07:16:54,372 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 68)
2018-03-19 07:16:54,382 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 68, learning rate is 0.0016002257186.
2018-03-19 07:23:36,592 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 69)
2018-03-19 07:23:36,605 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 69, learning rate is 0.0015220962487.
2018-03-19 07:28:14,767 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 70)
2018-03-19 07:28:14,777 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 70, learning rate is 0.00144778137445.
2018-03-19 07:36:49,735 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 71)
2018-03-19 07:36:49,744 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 71, learning rate is 0.00137709485192.
2018-03-19 07:41:32,548 [steps/libs/nnet3/train/frame_level_objf/common.py:201 - train_one_iteration - INFO ] Training neural net (pass 72)
2018-03-19 07:41:32,561 [steps/libs/nnet3/train/frame_level_objf/common.py:265 - train_one_iteration - INFO ] On iteration 72, learning rate is 0.0012.
2018-03-19 07:45:18,673 [steps/nnet3/train_raw_dnn.py:395 - train - INFO ] Doing final combination to produce final.raw
2018-03-19 07:45:18,673 [steps/libs/nnet3/train/frame_level_objf/common.py:466 - combine_models - INFO ] Combining set([64, 65, 66, 67, 68, 69, 70, 71, 72, 73, 54, 55, 56, 57, 58, 59, 60, 61, 62, 63]) models.
2018-03-19 07:55:23,280 [steps/nnet3/train_raw_dnn.py:417 - train - INFO ] Cleaning up the experiment directory exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0
exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0: num-iters=73 nj=2..8 num-params=29.7M combine=-0.57->-0.48
steps/nnet3/train_raw_dnn.py --stage=50 --cmd=run.pl --mem 4G --feat.cmvn-opts=--norm-means=false --norm-vars=false --trainer.num-epochs 2 --trainer.optimization.num-jobs-initial=2 --trainer.optimization.num-jobs-final=8 --trainer.optimization.initial-effective-lrate=0.0015 --trainer.optimization.final-effective-lrate=0.00015 --trainer.optimization.minibatch-size=256,128 --trainer.dropout-schedule=0,0.6,0 --trainer.samples-per-iter=400000 --trainer.max-param-change=2.0 --trainer.srand=0 --feat-dir data/101-recog-min/cv_train_nz_sp_hires --feat.online-ivector-dir exp/101-recog-min/nnet3/ivectors_cv_train_nz_sp --egs.dir exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/egs --use-dense-targets false --targets-scp exp/101-recog-min/tri4_cv_train_nz_ali --cleanup.remove-egs false --cleanup.preserve-model-interval 50 --use-gpu true --dir=exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0
['steps/nnet3/train_raw_dnn.py', '--stage=50', '--cmd=run.pl --mem 4G', '--feat.cmvn-opts=--norm-means=false --norm-vars=false', '--trainer.num-epochs', '2', '--trainer.optimization.num-jobs-initial=2', '--trainer.optimization.num-jobs-final=8', '--trainer.optimization.initial-effective-lrate=0.0015', '--trainer.optimization.final-effective-lrate=0.00015', '--trainer.optimization.minibatch-size=256,128', '--trainer.dropout-schedule=0,0.6,0', '--trainer.samples-per-iter=400000', '--trainer.max-param-change=2.0', '--trainer.srand=0', '--feat-dir', 'data/101-recog-min/cv_train_nz_sp_hires', '--feat.online-ivector-dir', 'exp/101-recog-min/nnet3/ivectors_cv_train_nz_sp', '--egs.dir', 'exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/egs', '--use-dense-targets', 'false', '--targets-scp', 'exp/101-recog-min/tri4_cv_train_nz_ali', '--cleanup.remove-egs', 'false', '--cleanup.preserve-model-interval', '50', '--use-gpu', 'true', '--dir=exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0']
nnet3-copy '--edits=rename-node old-name=output-0 new-name=output' exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/final.raw - 
nnet3-am-init exp/101-recog-min/tri4_cv_train_nz_ali/final.mdl - exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/final.mdl 
LOG (nnet3-copy[5.2.204~1-08848]:main():nnet3-copy.cc:114) Copied raw neural net from exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/final.raw to -
LOG (nnet3-am-init[5.2.204~1-08848]:main():nnet3-am-init.cc:96) Initialized am-nnet (neural net acoustic model) and wrote to exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/final.mdl
./multitask_run_2_base.sh: compute average posterior and readjust priors for language 01-recognition.
steps/nnet3/adjust_priors.sh exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/egs_aligns
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/101-recog-min/nnet3/ivectors_cv_dev_nz /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/101-recog-min/cv_dev_nz_hires exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_dev_nz
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_dev_nz
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_dev_nz/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,4,21) and mean=8.8
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_dev_nz/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/101-recog-min/cv_dev_nz_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_dev_nz
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/101-recog-min/nnet3/ivectors_cv_test_onlynz /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/101-recog-min/cv_test_onlynz_hires exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlynz
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlynz
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlynz/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(1,5,24) and mean=10.2
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlynz/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/101-recog-min/cv_test_onlynz_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlynz
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
steps/nnet3/decode.sh --nj 20 --cmd run.pl --mem 4G --stage -2 --beam 15.0 --lattice-beam 8.0 --skip-scoring false --online-ivector-dir exp/101-recog-min/nnet3/ivectors_cv_test_onlyindian /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg data/101-recog-min/cv_test_onlyindian_hires exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlyindian
steps/nnet2/check_ivectors_compatible.sh: WARNING: One of the directories do not contain iVector ID.
steps/nnet2/check_ivectors_compatible.sh: WARNING: That means it's you who's reponsible for keeping 
steps/nnet2/check_ivectors_compatible.sh: WARNING: the directories compatible
steps/nnet3/decode.sh: feature type is raw
steps/diagnostic/analyze_lats.sh --cmd run.pl --mem 4G --iter final /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlyindian
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlyindian/log/analyze_alignments.log
Overall, lattice depth (10,50,90-percentile)=(2,10,34) and mean=14.8
steps/diagnostic/analyze_lats.sh: see stats in exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlyindian/log/analyze_lattice_depth_stats.log
score best paths
local/score.sh --iter final --cmd run.pl --mem 4G data/101-recog-min/cv_test_onlyindian_hires /home/abhinav/kaldi/accents/exp/tri4/graph_sw1_tg exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlyindian
local/score.sh: scoring with word insertion penalty=0.0,0.5,1.0
score confidence and timing with sclite
Decoding done.
%WER 26.54 [ 2756 / 10386, 172 ins, 950 del, 1634 sub ] exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_dev_nz/wer_7_0.0
%WER 68.76 [ 559 / 813, 13 ins, 294 del, 252 sub ] exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlyindian/wer_7_0.0
%WER 33.13 [ 1686 / 5089, 88 ins, 574 del, 1024 sub ] exp/nnet3_combined/multitask_a300_t512_0.50.5_wcon_4drops_0+0.6+0/101-recog-min/decode_cv_test_onlynz/wer_7_0.0
